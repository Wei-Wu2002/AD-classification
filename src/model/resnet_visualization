digraph {
	graph [size="59.55,59.55"]
	node [align=left fontname=monospace fontsize=10 height=0.2 ranksep=0.1 shape=box style=filled]
	2181218536912 [label="
 (1, 2)" fillcolor=darkolivegreen1]
	2181218231792 [label=AddmmBackward0]
	2181218231648 -> 2181218231792
	2181218189040 [label="fc.bias
 (2)" fillcolor=lightblue]
	2181218189040 -> 2181218231648
	2181218231648 [label=AccumulateGrad]
	2181218231600 -> 2181218231792
	2181218231600 [label=ViewBackward0]
	2181218231504 -> 2181218231600
	2181218231504 [label=MeanBackward1]
	2181218231216 -> 2181218231504
	2181218231216 [label=ReluBackward0]
	2181218231120 -> 2181218231216
	2181218231120 [label=AddBackward0]
	2181218231024 -> 2181218231120
	2181218231024 [label=NativeBatchNormBackward0]
	2181218230880 -> 2181218231024
	2181218230880 [label=ConvolutionBackward0]
	2181218230592 -> 2181218230880
	2181218230592 [label=ReluBackward0]
	2181218230352 -> 2181218230592
	2181218230352 [label=NativeBatchNormBackward0]
	2181218232368 -> 2181218230352
	2181218232368 [label=ConvolutionBackward0]
	2181218231072 -> 2181218232368
	2181218231072 [label=ReluBackward0]
	2181218232656 -> 2181218231072
	2181218232656 [label=AddBackward0]
	2181218232752 -> 2181218232656
	2181218232752 [label=NativeBatchNormBackward0]
	2181218232896 -> 2181218232752
	2181218232896 [label=ConvolutionBackward0]
	2181218233088 -> 2181218232896
	2181218233088 [label=ReluBackward0]
	2181218233232 -> 2181218233088
	2181218233232 [label=NativeBatchNormBackward0]
	2181218233328 -> 2181218233232
	2181218233328 [label=ConvolutionBackward0]
	2181218233520 -> 2181218233328
	2181218233520 [label=ReluBackward0]
	2181218233664 -> 2181218233520
	2181218233664 [label=AddBackward0]
	2181218233760 -> 2181218233664
	2181218233760 [label=NativeBatchNormBackward0]
	2181218233904 -> 2181218233760
	2181218233904 [label=ConvolutionBackward0]
	2181218234096 -> 2181218233904
	2181218234096 [label=ReluBackward0]
	2181218234240 -> 2181218234096
	2181218234240 [label=NativeBatchNormBackward0]
	2181218234336 -> 2181218234240
	2181218234336 [label=ConvolutionBackward0]
	2181218233712 -> 2181218234336
	2181218233712 [label=ReluBackward0]
	2181218234624 -> 2181218233712
	2181218234624 [label=AddBackward0]
	2181218234720 -> 2181218234624
	2181218234720 [label=NativeBatchNormBackward0]
	2181218234864 -> 2181218234720
	2181218234864 [label=ConvolutionBackward0]
	2181218235056 -> 2181218234864
	2181218235056 [label=ReluBackward0]
	2181218235200 -> 2181218235056
	2181218235200 [label=NativeBatchNormBackward0]
	2181218235296 -> 2181218235200
	2181218235296 [label=ConvolutionBackward0]
	2181218235488 -> 2181218235296
	2181218235488 [label=ReluBackward0]
	2181218235632 -> 2181218235488
	2181218235632 [label=AddBackward0]
	2181218235728 -> 2181218235632
	2181218235728 [label=NativeBatchNormBackward0]
	2181218235872 -> 2181218235728
	2181218235872 [label=ConvolutionBackward0]
	2181218236064 -> 2181218235872
	2181218236064 [label=ReluBackward0]
	2181218236208 -> 2181218236064
	2181218236208 [label=NativeBatchNormBackward0]
	2181218236304 -> 2181218236208
	2181218236304 [label=ConvolutionBackward0]
	2181218235680 -> 2181218236304
	2181218235680 [label=ReluBackward0]
	2181218236592 -> 2181218235680
	2181218236592 [label=AddBackward0]
	2181218236688 -> 2181218236592
	2181218236688 [label=NativeBatchNormBackward0]
	2181218236832 -> 2181218236688
	2181218236832 [label=ConvolutionBackward0]
	2181218237024 -> 2181218236832
	2181218237024 [label=ReluBackward0]
	2181218237168 -> 2181218237024
	2181218237168 [label=NativeBatchNormBackward0]
	2181218237264 -> 2181218237168
	2181218237264 [label=ConvolutionBackward0]
	2181218237456 -> 2181218237264
	2181218237456 [label=ReluBackward0]
	2181218237600 -> 2181218237456
	2181218237600 [label=AddBackward0]
	2181218237696 -> 2181218237600
	2181218237696 [label=NativeBatchNormBackward0]
	2181218237840 -> 2181218237696
	2181218237840 [label=ConvolutionBackward0]
	2181218238032 -> 2181218237840
	2181218238032 [label=ReluBackward0]
	2181218238176 -> 2181218238032
	2181218238176 [label=NativeBatchNormBackward0]
	2181218238272 -> 2181218238176
	2181218238272 [label=ConvolutionBackward0]
	2181218237648 -> 2181218238272
	2181218237648 [label=ReluBackward0]
	2181218582688 -> 2181218237648
	2181218582688 [label=AddBackward0]
	2181218582784 -> 2181218582688
	2181218582784 [label=NativeBatchNormBackward0]
	2181218582928 -> 2181218582784
	2181218582928 [label=ConvolutionBackward0]
	2181218583120 -> 2181218582928
	2181218583120 [label=ReluBackward0]
	2181218583264 -> 2181218583120
	2181218583264 [label=NativeBatchNormBackward0]
	2181218583360 -> 2181218583264
	2181218583360 [label=ConvolutionBackward0]
	2181218582736 -> 2181218583360
	2181218582736 [label=MaxPool2DWithIndicesBackward0]
	2181218583648 -> 2181218582736
	2181218583648 [label=ReluBackward0]
	2181218583744 -> 2181218583648
	2181218583744 [label=NativeBatchNormBackward0]
	2181218583792 -> 2181218583744
	2181218583792 [label=ConvolutionBackward0]
	2181218584080 -> 2181218583792
	2181214753168 [label="conv1.weight
 (64, 3, 7, 7)" fillcolor=lightblue]
	2181214753168 -> 2181218584080
	2181218584080 [label=AccumulateGrad]
	2181218583456 -> 2181218583744
	2181192700400 [label="bn1.weight
 (64)" fillcolor=lightblue]
	2181192700400 -> 2181218583456
	2181218583456 [label=AccumulateGrad]
	2181218583888 -> 2181218583744
	2181192501680 [label="bn1.bias
 (64)" fillcolor=lightblue]
	2181192501680 -> 2181218583888
	2181218583888 [label=AccumulateGrad]
	2181218583552 -> 2181218583360
	2181192502064 [label="layer1.0.conv1.weight
 (64, 64, 3, 3)" fillcolor=lightblue]
	2181192502064 -> 2181218583552
	2181218583552 [label=AccumulateGrad]
	2181218583312 -> 2181218583264
	2181218178192 [label="layer1.0.bn1.weight
 (64)" fillcolor=lightblue]
	2181218178192 -> 2181218583312
	2181218583312 [label=AccumulateGrad]
	2181218583168 -> 2181218583264
	2181218178288 [label="layer1.0.bn1.bias
 (64)" fillcolor=lightblue]
	2181218178288 -> 2181218583168
	2181218583168 [label=AccumulateGrad]
	2181218583072 -> 2181218582928
	2181218178672 [label="layer1.0.conv2.weight
 (64, 64, 3, 3)" fillcolor=lightblue]
	2181218178672 -> 2181218583072
	2181218583072 [label=AccumulateGrad]
	2181218582880 -> 2181218582784
	2181218178768 [label="layer1.0.bn2.weight
 (64)" fillcolor=lightblue]
	2181218178768 -> 2181218582880
	2181218582880 [label=AccumulateGrad]
	2181218582832 -> 2181218582784
	2181218178864 [label="layer1.0.bn2.bias
 (64)" fillcolor=lightblue]
	2181218178864 -> 2181218582832
	2181218582832 [label=AccumulateGrad]
	2181218582736 -> 2181218582688
	2181218238416 -> 2181218238272
	2181218179248 [label="layer1.1.conv1.weight
 (64, 64, 3, 3)" fillcolor=lightblue]
	2181218179248 -> 2181218238416
	2181218238416 [label=AccumulateGrad]
	2181218238224 -> 2181218238176
	2181218179344 [label="layer1.1.bn1.weight
 (64)" fillcolor=lightblue]
	2181218179344 -> 2181218238224
	2181218238224 [label=AccumulateGrad]
	2181218238080 -> 2181218238176
	2181218179440 [label="layer1.1.bn1.bias
 (64)" fillcolor=lightblue]
	2181218179440 -> 2181218238080
	2181218238080 [label=AccumulateGrad]
	2181218237984 -> 2181218237840
	2181218179824 [label="layer1.1.conv2.weight
 (64, 64, 3, 3)" fillcolor=lightblue]
	2181218179824 -> 2181218237984
	2181218237984 [label=AccumulateGrad]
	2181218237792 -> 2181218237696
	2181218179920 [label="layer1.1.bn2.weight
 (64)" fillcolor=lightblue]
	2181218179920 -> 2181218237792
	2181218237792 [label=AccumulateGrad]
	2181218237744 -> 2181218237696
	2181218180016 [label="layer1.1.bn2.bias
 (64)" fillcolor=lightblue]
	2181218180016 -> 2181218237744
	2181218237744 [label=AccumulateGrad]
	2181218237648 -> 2181218237600
	2181218237408 -> 2181218237264
	2181218180400 [label="layer2.0.conv1.weight
 (128, 64, 3, 3)" fillcolor=lightblue]
	2181218180400 -> 2181218237408
	2181218237408 [label=AccumulateGrad]
	2181218237216 -> 2181218237168
	2181218180496 [label="layer2.0.bn1.weight
 (128)" fillcolor=lightblue]
	2181218180496 -> 2181218237216
	2181218237216 [label=AccumulateGrad]
	2181218237072 -> 2181218237168
	2181218180592 [label="layer2.0.bn1.bias
 (128)" fillcolor=lightblue]
	2181218180592 -> 2181218237072
	2181218237072 [label=AccumulateGrad]
	2181218236976 -> 2181218236832
	2181218180976 [label="layer2.0.conv2.weight
 (128, 128, 3, 3)" fillcolor=lightblue]
	2181218180976 -> 2181218236976
	2181218236976 [label=AccumulateGrad]
	2181218236784 -> 2181218236688
	2181218181072 [label="layer2.0.bn2.weight
 (128)" fillcolor=lightblue]
	2181218181072 -> 2181218236784
	2181218236784 [label=AccumulateGrad]
	2181218236736 -> 2181218236688
	2181218181168 [label="layer2.0.bn2.bias
 (128)" fillcolor=lightblue]
	2181218181168 -> 2181218236736
	2181218236736 [label=AccumulateGrad]
	2181218236640 -> 2181218236592
	2181218236640 [label=NativeBatchNormBackward0]
	2181218237360 -> 2181218236640
	2181218237360 [label=ConvolutionBackward0]
	2181218237456 -> 2181218237360
	2181218237504 -> 2181218237360
	2181218181552 [label="layer2.0.downsample.0.weight
 (128, 64, 1, 1)" fillcolor=lightblue]
	2181218181552 -> 2181218237504
	2181218237504 [label=AccumulateGrad]
	2181218236928 -> 2181218236640
	2181218181648 [label="layer2.0.downsample.1.weight
 (128)" fillcolor=lightblue]
	2181218181648 -> 2181218236928
	2181218236928 [label=AccumulateGrad]
	2181218236880 -> 2181218236640
	2181218181744 [label="layer2.0.downsample.1.bias
 (128)" fillcolor=lightblue]
	2181218181744 -> 2181218236880
	2181218236880 [label=AccumulateGrad]
	2181218236496 -> 2181218236304
	2181218182128 [label="layer2.1.conv1.weight
 (128, 128, 3, 3)" fillcolor=lightblue]
	2181218182128 -> 2181218236496
	2181218236496 [label=AccumulateGrad]
	2181218236256 -> 2181218236208
	2181218182224 [label="layer2.1.bn1.weight
 (128)" fillcolor=lightblue]
	2181218182224 -> 2181218236256
	2181218236256 [label=AccumulateGrad]
	2181218236112 -> 2181218236208
	2181218182320 [label="layer2.1.bn1.bias
 (128)" fillcolor=lightblue]
	2181218182320 -> 2181218236112
	2181218236112 [label=AccumulateGrad]
	2181218236016 -> 2181218235872
	2181218182704 [label="layer2.1.conv2.weight
 (128, 128, 3, 3)" fillcolor=lightblue]
	2181218182704 -> 2181218236016
	2181218236016 [label=AccumulateGrad]
	2181218235824 -> 2181218235728
	2181218182800 [label="layer2.1.bn2.weight
 (128)" fillcolor=lightblue]
	2181218182800 -> 2181218235824
	2181218235824 [label=AccumulateGrad]
	2181218235776 -> 2181218235728
	2181218182896 [label="layer2.1.bn2.bias
 (128)" fillcolor=lightblue]
	2181218182896 -> 2181218235776
	2181218235776 [label=AccumulateGrad]
	2181218235680 -> 2181218235632
	2181218235440 -> 2181218235296
	2181218183280 [label="layer3.0.conv1.weight
 (256, 128, 3, 3)" fillcolor=lightblue]
	2181218183280 -> 2181218235440
	2181218235440 [label=AccumulateGrad]
	2181218235248 -> 2181218235200
	2181218183376 [label="layer3.0.bn1.weight
 (256)" fillcolor=lightblue]
	2181218183376 -> 2181218235248
	2181218235248 [label=AccumulateGrad]
	2181218235104 -> 2181218235200
	2181218183472 [label="layer3.0.bn1.bias
 (256)" fillcolor=lightblue]
	2181218183472 -> 2181218235104
	2181218235104 [label=AccumulateGrad]
	2181218235008 -> 2181218234864
	2181218183856 [label="layer3.0.conv2.weight
 (256, 256, 3, 3)" fillcolor=lightblue]
	2181218183856 -> 2181218235008
	2181218235008 [label=AccumulateGrad]
	2181218234816 -> 2181218234720
	2181218183952 [label="layer3.0.bn2.weight
 (256)" fillcolor=lightblue]
	2181218183952 -> 2181218234816
	2181218234816 [label=AccumulateGrad]
	2181218234768 -> 2181218234720
	2181218184048 [label="layer3.0.bn2.bias
 (256)" fillcolor=lightblue]
	2181218184048 -> 2181218234768
	2181218234768 [label=AccumulateGrad]
	2181218234672 -> 2181218234624
	2181218234672 [label=NativeBatchNormBackward0]
	2181218235392 -> 2181218234672
	2181218235392 [label=ConvolutionBackward0]
	2181218235488 -> 2181218235392
	2181218235536 -> 2181218235392
	2181218184432 [label="layer3.0.downsample.0.weight
 (256, 128, 1, 1)" fillcolor=lightblue]
	2181218184432 -> 2181218235536
	2181218235536 [label=AccumulateGrad]
	2181218234960 -> 2181218234672
	2181218184528 [label="layer3.0.downsample.1.weight
 (256)" fillcolor=lightblue]
	2181218184528 -> 2181218234960
	2181218234960 [label=AccumulateGrad]
	2181218234912 -> 2181218234672
	2181218184624 [label="layer3.0.downsample.1.bias
 (256)" fillcolor=lightblue]
	2181218184624 -> 2181218234912
	2181218234912 [label=AccumulateGrad]
	2181218234528 -> 2181218234336
	2181218185008 [label="layer3.1.conv1.weight
 (256, 256, 3, 3)" fillcolor=lightblue]
	2181218185008 -> 2181218234528
	2181218234528 [label=AccumulateGrad]
	2181218234288 -> 2181218234240
	2181218185104 [label="layer3.1.bn1.weight
 (256)" fillcolor=lightblue]
	2181218185104 -> 2181218234288
	2181218234288 [label=AccumulateGrad]
	2181218234144 -> 2181218234240
	2181218185200 [label="layer3.1.bn1.bias
 (256)" fillcolor=lightblue]
	2181218185200 -> 2181218234144
	2181218234144 [label=AccumulateGrad]
	2181218234048 -> 2181218233904
	2181218185584 [label="layer3.1.conv2.weight
 (256, 256, 3, 3)" fillcolor=lightblue]
	2181218185584 -> 2181218234048
	2181218234048 [label=AccumulateGrad]
	2181218233856 -> 2181218233760
	2181218185680 [label="layer3.1.bn2.weight
 (256)" fillcolor=lightblue]
	2181218185680 -> 2181218233856
	2181218233856 [label=AccumulateGrad]
	2181218233808 -> 2181218233760
	2181218185776 [label="layer3.1.bn2.bias
 (256)" fillcolor=lightblue]
	2181218185776 -> 2181218233808
	2181218233808 [label=AccumulateGrad]
	2181218233712 -> 2181218233664
	2181218233472 -> 2181218233328
	2181218186160 [label="layer4.0.conv1.weight
 (512, 256, 3, 3)" fillcolor=lightblue]
	2181218186160 -> 2181218233472
	2181218233472 [label=AccumulateGrad]
	2181218233280 -> 2181218233232
	2181218186256 [label="layer4.0.bn1.weight
 (512)" fillcolor=lightblue]
	2181218186256 -> 2181218233280
	2181218233280 [label=AccumulateGrad]
	2181218233136 -> 2181218233232
	2181218186352 [label="layer4.0.bn1.bias
 (512)" fillcolor=lightblue]
	2181218186352 -> 2181218233136
	2181218233136 [label=AccumulateGrad]
	2181218233040 -> 2181218232896
	2181218186736 [label="layer4.0.conv2.weight
 (512, 512, 3, 3)" fillcolor=lightblue]
	2181218186736 -> 2181218233040
	2181218233040 [label=AccumulateGrad]
	2181218232848 -> 2181218232752
	2181218186832 [label="layer4.0.bn2.weight
 (512)" fillcolor=lightblue]
	2181218186832 -> 2181218232848
	2181218232848 [label=AccumulateGrad]
	2181218232800 -> 2181218232752
	2181218186928 [label="layer4.0.bn2.bias
 (512)" fillcolor=lightblue]
	2181218186928 -> 2181218232800
	2181218232800 [label=AccumulateGrad]
	2181218232704 -> 2181218232656
	2181218232704 [label=NativeBatchNormBackward0]
	2181218233424 -> 2181218232704
	2181218233424 [label=ConvolutionBackward0]
	2181218233520 -> 2181218233424
	2181218233568 -> 2181218233424
	2181218187312 [label="layer4.0.downsample.0.weight
 (512, 256, 1, 1)" fillcolor=lightblue]
	2181218187312 -> 2181218233568
	2181218233568 [label=AccumulateGrad]
	2181218232992 -> 2181218232704
	2181218187408 [label="layer4.0.downsample.1.weight
 (512)" fillcolor=lightblue]
	2181218187408 -> 2181218232992
	2181218232992 [label=AccumulateGrad]
	2181218232944 -> 2181218232704
	2181218187504 [label="layer4.0.downsample.1.bias
 (512)" fillcolor=lightblue]
	2181218187504 -> 2181218232944
	2181218232944 [label=AccumulateGrad]
	2181218232560 -> 2181218232368
	2181218187888 [label="layer4.1.conv1.weight
 (512, 512, 3, 3)" fillcolor=lightblue]
	2181218187888 -> 2181218232560
	2181218232560 [label=AccumulateGrad]
	2181218230304 -> 2181218230352
	2181218187984 [label="layer4.1.bn1.weight
 (512)" fillcolor=lightblue]
	2181218187984 -> 2181218230304
	2181218230304 [label=AccumulateGrad]
	2181218230496 -> 2181218230352
	2181218188080 [label="layer4.1.bn1.bias
 (512)" fillcolor=lightblue]
	2181218188080 -> 2181218230496
	2181218230496 [label=AccumulateGrad]
	2181218230640 -> 2181218230880
	2181218188464 [label="layer4.1.conv2.weight
 (512, 512, 3, 3)" fillcolor=lightblue]
	2181218188464 -> 2181218230640
	2181218230640 [label=AccumulateGrad]
	2181218230928 -> 2181218231024
	2181218188560 [label="layer4.1.bn2.weight
 (512)" fillcolor=lightblue]
	2181218188560 -> 2181218230928
	2181218230928 [label=AccumulateGrad]
	2181218230976 -> 2181218231024
	2181218188656 [label="layer4.1.bn2.bias
 (512)" fillcolor=lightblue]
	2181218188656 -> 2181218230976
	2181218230976 [label=AccumulateGrad]
	2181218231072 -> 2181218231120
	2181218231552 -> 2181218231792
	2181218231552 [label=TBackward0]
	2181218231168 -> 2181218231552
	2181218188944 [label="fc.weight
 (2, 512)" fillcolor=lightblue]
	2181218188944 -> 2181218231168
	2181218231168 [label=AccumulateGrad]
	2181218231792 -> 2181218536912
}
